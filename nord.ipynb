{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from wordcloud import STOPWORDS, WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import string\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "\n",
        "rcParams['figure.figsize'] = 15, 7\n",
        "\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "ner = spacy.load('en_core_web_sm')\n",
        "\n",
        "\n",
        "import string\n",
        "import unicodedata\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "from wordcloud import STOPWORDS, WordCloud\n",
        "\n",
        "rcParams['figure.figsize'] = 15, 7\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "from autocorrect import Speller, spell\n",
        "from bs4 import BeautifulSoup\n",
        "from contractions import contractions_dict\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from wordcloud import STOPWORDS, WordCloud\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from textblob import TextBlob    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>date</th>\n",
              "      <th>verified</th>\n",
              "      <th>author</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Finally Settled for Average Performance and Ba...</td>\n",
              "      <td>For 25K , you will get - Average performance. ...</td>\n",
              "      <td>30-Sep-20</td>\n",
              "      <td>Yes</td>\n",
              "      <td>arv</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6gb+64gb not worth buying, storage issues are ...</td>\n",
              "      <td>The phone is really great performance wise, th...</td>\n",
              "      <td>26-Sep-20</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Shivani</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Perfect phone for light to moderate usage</td>\n",
              "      <td>I have been using it since 14-15 days. So here...</td>\n",
              "      <td>27-Sep-20</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Simranjit Singh</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Love this phone from one plus</td>\n",
              "      <td>Such a nice phone from one plus.over all it's ...</td>\n",
              "      <td>26-Sep-20</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Rohit Sahu</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Never a oneplus standard in terms of sale, and...</td>\n",
              "      <td>Regarding the one plus feeling. It's gone.. Se...</td>\n",
              "      <td>30-Sep-20</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>Nice</td>\n",
              "      <td>Good</td>\n",
              "      <td>05-Dec-20</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>Hajah</td>\n",
              "      <td>Very bad</td>\n",
              "      <td>05-Feb-21</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Esa</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704</th>\n",
              "      <td>Nce</td>\n",
              "      <td>Super</td>\n",
              "      <td>19-Mar-21</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Nageshwar Goud</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>705</th>\n",
              "      <td>Waste of money.</td>\n",
              "      <td>Worst product. Nevar purchase renewd product</td>\n",
              "      <td>01-Jan-21</td>\n",
              "      <td>Yes</td>\n",
              "      <td>John</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>706</th>\n",
              "      <td>Received Faulty product me bye amazone seller</td>\n",
              "      <td>I have purchased 10 feb 2021 and insert sim to...</td>\n",
              "      <td>18-Feb-21</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Prashant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>707 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 title  \\\n",
              "0    Finally Settled for Average Performance and Ba...   \n",
              "1    6gb+64gb not worth buying, storage issues are ...   \n",
              "2            Perfect phone for light to moderate usage   \n",
              "3                        Love this phone from one plus   \n",
              "4    Never a oneplus standard in terms of sale, and...   \n",
              "..                                                 ...   \n",
              "702                                               Nice   \n",
              "703                                              Hajah   \n",
              "704                                                Nce   \n",
              "705                                    Waste of money.   \n",
              "706      Received Faulty product me bye amazone seller   \n",
              "\n",
              "                                               content       date verified  \\\n",
              "0    For 25K , you will get - Average performance. ...  30-Sep-20      Yes   \n",
              "1    The phone is really great performance wise, th...  26-Sep-20      Yes   \n",
              "2    I have been using it since 14-15 days. So here...  27-Sep-20      Yes   \n",
              "3    Such a nice phone from one plus.over all it's ...  26-Sep-20      Yes   \n",
              "4    Regarding the one plus feeling. It's gone.. Se...  30-Sep-20      Yes   \n",
              "..                                                 ...        ...      ...   \n",
              "702                                               Good  05-Dec-20      Yes   \n",
              "703                                           Very bad  05-Feb-21      Yes   \n",
              "704                                              Super  19-Mar-21      Yes   \n",
              "705       Worst product. Nevar purchase renewd product  01-Jan-21      Yes   \n",
              "706  I have purchased 10 feb 2021 and insert sim to...  18-Feb-21      Yes   \n",
              "\n",
              "              author  rating  \n",
              "0                arv       2  \n",
              "1            Shivani       2  \n",
              "2    Simranjit Singh       5  \n",
              "3         Rohit Sahu       4  \n",
              "4    Amazon Customer       2  \n",
              "..               ...     ...  \n",
              "702  Amazon Customer       5  \n",
              "703              Esa       5  \n",
              "704   Nageshwar Goud       5  \n",
              "705             John       1  \n",
              "706         Prashant       1  \n",
              "\n",
              "[707 rows x 6 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nord = pd.read_csv('nord.csv')\n",
        "nord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kdDBqZYC07JC",
        "outputId": "6df1a65e-8048-4529-8368-66bdccfbe234"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(706, list)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Load the dataset\n",
        "docs_raw = nord.content.dropna().to_list()\n",
        "len(docs_raw), type(docs_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "snowball_stemmer = SnowballStemmer('english')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "contractions_dict = {     \n",
        "    \"ain't\": \"am not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"can't've\": \"cannot have\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he had\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'll've\": \"he will have\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"I'd\": \"I had\",\n",
        "    \"I'd've\": \"I would have\",\n",
        "    \"I'll\": \"I will\",\n",
        "    \"I'll've\": \"I will have\",\n",
        "    \"I'm\": \"I am\",\n",
        "    \"I've\": \"I have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it had\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"iit will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she had\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so is\",\n",
        "    \"that'd\": \"that had\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there had\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they had\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we had\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you had\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\"\n",
        "    }\n",
        "\n",
        "def lemmatize( text):\n",
        "    \"\"\"\n",
        "    take string input and lemmatize the words.\n",
        "    use WordNetLemmatizer to lemmatize the words.\n",
        "    \"\"\"\n",
        "    word_tokens = nltk.word_tokenize(text)\n",
        "    lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in word_tokens]\n",
        "    return (\" \".join(lemmatized_word))\n",
        "\n",
        "def remove_numbers(text):\n",
        "    \"\"\"\n",
        "    take string input and return a clean text without numbers. \n",
        "    Use regex to discard the numbers.\n",
        "    \"\"\"\n",
        "    output = ''.join(c for c in text if not c.isdigit())\n",
        "    return output\n",
        "\n",
        "def remove_punct(text):\n",
        "    \"\"\"\n",
        "    take string input and clean string without punctuations.\n",
        "    use regex to remove the punctuations.\n",
        "    \"\"\"\n",
        "    return ''.join(c for c in text if c not in punctuation)\n",
        "\n",
        "def remove_stopwords(sentence):\n",
        "    \"\"\"\n",
        "    removes all the stop words like \"is,the,a, etc.\"\n",
        "    5 lines of code can be written in one line as:\n",
        "        return ' '.join([w for w in word_tokenize(sentence) if not w in stop_words]) \n",
        "    \"\"\"\n",
        "    clean_sent =[]\n",
        "    for w in word_tokenize(sentence):\n",
        "        if not w in stop_words:\n",
        "            clean_sent.append(w)\n",
        "    return \" \".join(clean_sent)\n",
        "\n",
        "def remove_Tags(text):\n",
        "    \"\"\"\n",
        "    take string input and clean string without tags.\n",
        "    use regex to remove the html tags.\n",
        "    \"\"\"\n",
        "    cleaned_text = re.sub('<[^<]+?>','', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    stripped_text = soup.get_text()\n",
        "    return stripped_text\n",
        "\n",
        "def sentence_tokenize(text):\n",
        "    \"\"\"\n",
        "    take string input and return list of sentences.\n",
        "    use nltk.sent_tokenize() to split the sentences.\n",
        "    \"\"\"\n",
        "    sent_list=[]\n",
        "    for w in nltk.sent_tokenize(text):\n",
        "        sent_list.append(w)\n",
        "    return sent_list\n",
        "\n",
        "def autospell(text):\n",
        "    \"\"\"\n",
        "    correct the spelling of the word.\n",
        "    \"\"\"\n",
        "    spells = [Speller().autocorrect_word(w) for w in (nltk.word_tokenize(text))]\n",
        "    return \" \".join(spells)\n",
        "\n",
        "def stemming(text):\n",
        "    \"\"\"\n",
        "    take string input and stem the words.\n",
        "    use snowball_stemmer to stem the string.\n",
        "    \"\"\"\n",
        "    word_tokens = nltk.word_tokenize(text)\n",
        "    stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]\n",
        "    return \" \".join(stemmed_word)\n",
        "\n",
        "def to_lower(text):\n",
        "    \"\"\"\n",
        "    Converting text to lower case as in, converting \"Hello\" to \"hello\" or \"HELLO\" to \"hello\".\n",
        "    \"\"\"\n",
        "    return ' '.join([w.lower() for w in word_tokenize(text)])\n",
        "\n",
        "def word_tokenize( text):\n",
        "    \"\"\"\n",
        "    take string input and return list of words.\n",
        "    use nltk.word_tokenize() to split the words.\n",
        "    \"\"\"\n",
        "    word_list=[]\n",
        "    for sentences in nltk.sent_tokenize(text):\n",
        "        for words in nltk.word_tokenize(sentences):\n",
        "            word_list.append(words)\n",
        "    return word_list\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "    #remove_accented_chars('Sómě Áccěntěd těxt')\n",
        "\n",
        "def expand_contractions(text, contractions_dict):\n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
        "                                    flags=re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contractions_dict.get(match) \\\n",
        "            if contractions_dict.get(match) \\\n",
        "            else contractions_dict.get(match.lower())\n",
        "        expanded_contraction = expanded_contraction\n",
        "        return expanded_contraction\n",
        "\n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text\n",
        "\n",
        "def pre_process1( text):\n",
        "    \"\"\"\n",
        "    \"\"\"    \n",
        "    text = remove_accented_chars(text)\n",
        "    text = expand_contractions(text, contractions_dict)\n",
        "    text = remove_punct(text)\n",
        "    text = autospell(text)\n",
        "    text = to_lower(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = remove_numbers(text)\n",
        "    text = lemmatize(text)\n",
        "    text = stemming(text)\n",
        "    text = word_tokenize(text)\n",
        "    return ' '.join(text)\n",
        "    \n",
        "\n",
        "\n",
        "def pre_process2(text):\n",
        "        lower_text = to_lower(text)\n",
        "        sentence_tokens = sentence_tokenize(lower_text)\n",
        "        word_list = []\n",
        "        for each_sent in sentence_tokens:\n",
        "            lemmatizzed_sent = lemmatize(each_sent)\n",
        "            clean_text = remove_numbers(lemmatizzed_sent)\n",
        "            clean_text = remove_punct(clean_text)\n",
        "            clean_text = remove_Tags(clean_text)\n",
        "            clean_text = remove_stopwords(clean_text)\n",
        "            word_tokens = word_tokenize(clean_text)\n",
        "            for i in word_tokens:\n",
        "                word_list.append(i)\n",
        "        return word_list\n",
        "\n",
        "def pre_processing3(document):\n",
        "  #1. Remove Punctuations\n",
        "  sentWithoutPunct = ''.join([char for char in document  if char not in string.punctuation])\n",
        "  #2. Extract words out of the sentences\n",
        "  words = sentWithoutPunct.split()\n",
        "  #3. Normalize the data (lowercase)\n",
        "  wordNormalized = [word.lower() for word in words]\n",
        "  # 4. Remove Stopwords\n",
        "  vocabulary = [word for word in wordNormalized if word not in stopwords.words('english')]\n",
        "  # 5. Apply Stemming\n",
        "  # a. Exclude those words with NER prop \n",
        "  ner_words = [tokens.text for tokens in ner(document).ents]\n",
        "  # b. perform Stemming with other words\n",
        "  stemmed = [PorterStemmer().stem(word) for word in vocabulary if word not in ner_words]\n",
        "\n",
        "  return stemmed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "HTTPError",
          "evalue": "HTTP Error 400: Bad Request",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12912/2137072497.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpreprocessed_docs_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcontent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs_raw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_language\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'en'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mpreprocessed_docs_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_process1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\Python_3_7\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36mdetect_language\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         )\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\Python_3_7\\lib\\site-packages\\textblob\\translate.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, source, host, type_)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mclient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"te\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         )\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\Python_3_7\\lib\\site-packages\\textblob\\translate.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, url, host, type_, data)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhost\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_proxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\Python_3_7\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\Python_3_7\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\Python_3_7\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\Python_3_7\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\Python_3_7\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\Python_3_7\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
          ]
        }
      ],
      "source": [
        "preprocessed_docs_raw = []\n",
        "for content in docs_raw: \n",
        "    if TextBlob(content).detect_language() == 'en':\n",
        "        preprocessed_docs_raw.append(pre_process1(content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "706"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_raw = preprocessed_docs_raw\n",
        "len(docs_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUNFSOgY07JD"
      },
      "outputs": [],
      "source": [
        "#Create Document Term Matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "tf_vectorizer = CountVectorizer(stop_words='english', #Stopwords\n",
        "                               lowercase=True, # Normalization\n",
        "                               token_pattern= r'\\b[a-zA-Z]{3,}', #Tokenization\n",
        "                                # max_df=0.5,\n",
        "                                # min_df=1.0,\n",
        "                                strip_accents='unicode' #Trims all unicode chars which is not a part of eng language\n",
        "                               )\n",
        "\n",
        "tfObject = tf_vectorizer.fit_transform(docs_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrzQMir307JE",
        "outputId": "0444c51e-a11e-4ce8-d1db-5191baab9ebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(706, 1179)\n"
          ]
        }
      ],
      "source": [
        "print(tfObject.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyPju0E-07JE",
        "outputId": "fcb42be2-2338-4b87-a3ad-2eb90f1f4907"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vikas\\anaconda3\\envs\\Python_3_7\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1804: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'numpy.int64'> 'dtype' will be converted to np.float64.\n",
            "  UserWarning)\n"
          ]
        }
      ],
      "source": [
        "#Create TF-IDF\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidfVectorizer = TfidfVectorizer(**tf_vectorizer.get_params())\n",
        "tfidfObject = tfidfVectorizer.fit_transform(docs_raw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLXqx0Zc07JF",
        "outputId": "f639c8fa-3936-4992-d588-821d2cfd1c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(706, 1179)\n"
          ]
        }
      ],
      "source": [
        "print(tfidfObject.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phun7ELb07JG",
        "outputId": "b31a3ef7-0bdf-4747-f2b3-b95443b8f368"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=4, random_state=0)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Apply LDA to create topic clusters for Bag of Words\n",
        "\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda_tf = LatentDirichletAllocation(n_components=4 , random_state=0)\n",
        "lda_tf.fit(tfObject) # as per books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Micx21907JG",
        "outputId": "15375175-a11f-47aa-f108-bbbe0d037b14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=4, random_state=0)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda_tfIDF = LatentDirichletAllocation(n_components=4 , random_state=0)\n",
        "lda_tfIDF.fit(tfidfObject) # as per seasoned DS considering memory optimizn reqd for handling Bigdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny_gWe_d07JH"
      },
      "outputs": [],
      "source": [
        "#Visualizing the LDA model\n",
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "pyLDAvis.enable_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-HJOo3b07JI",
        "outputId": "a09a09d3-bcd1-47a4-b5b5-84c7c9e636e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vikas\\anaconda3\\envs\\Python_3_7\\lib\\site-packages\\pyLDAvis\\_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el2678412573632258002645067259\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el2678412573632258002645067259_data = {\"mdsDat\": {\"x\": [0.08344391289593721, 0.07206706935710476, 0.06211222322948578, -0.21762320548252778], \"y\": [-0.07999489372827319, 0.11151813207165764, -0.02939165134546673, -0.0021315869979175975], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [33.718635579870785, 28.61826866770062, 23.449329812280546, 14.21376594014806]}, \"tinfo\": {\"Term\": [\"good\", \"product\", \"nice\", \"amazon\", \"bad\", \"valu\", \"servic\", \"money\", \"return\", \"renew\", \"storag\", \"camera\", \"item\", \"batteri\", \"custom\", \"worst\", \"replac\", \"buy\", \"best\", \"box\", \"care\", \"mobil\", \"awesom\", \"purchas\", \"month\", \"new\", \"oplus\", \"defect\", \"amaz\", \"like\", \"browser\", \"html\", \"month\", \"touch\", \"segment\", \"team\", \"proper\", \"trust\", \"oplus\", \"soo\", \"start\", \"exchang\", \"scroll\", \"internet\", \"font\", \"special\", \"sell\", \"base\", \"awesom\", \"present\", \"function\", \"motion\", \"faster\", \"compromis\", \"temperatur\", \"hrtz\", \"perfect\", \"point\", \"automat\", \"easili\", \"best\", \"work\", \"video\", \"super\", \"issu\", \"softwar\", \"fine\", \"budget\", \"mobil\", \"excel\", \"phone\", \"smooth\", \"superb\", \"selfi\", \"qualiti\", \"camera\", \"great\", \"support\", \"oneplus\", \"use\", \"face\", \"heat\", \"hang\", \"price\", \"better\", \"perform\", \"nord\", \"problem\", \"plus\", \"display\", \"batteri\", \"screen\", \"buy\", \"variant\", \"experi\", \"good\", \"valu\", \"design\", \"packag\", \"fps\", \"clear\", \"capac\", \"colour\", \"close\", \"wonder\", \"gorilla\", \"drop\", \"wide\", \"dislik\", \"easi\", \"cheap\", \"level\", \"definit\", \"pack\", \"data\", \"play\", \"piec\", \"backup\", \"money\", \"good\", \"arrang\", \"hai\", \"busi\", \"oper\", \"upgrad\", \"line\", \"bit\", \"day\", \"littl\", \"wast\", \"overal\", \"come\", \"look\", \"batteri\", \"charg\", \"life\", \"rang\", \"fast\", \"pictur\", \"love\", \"feel\", \"phone\", \"camera\", \"qualiti\", \"like\", \"price\", \"worth\", \"smartphon\", \"everyth\", \"use\", \"display\", \"product\", \"nord\", \"game\", \"realli\", \"bad\", \"oneplus\", \"problem\", \"better\", \"memori\", \"small\", \"cloud\", \"space\", \"deal\", \"expand\", \"notch\", \"outstand\", \"weight\", \"visibl\", \"netflix\", \"zero\", \"afford\", \"pixel\", \"chrome\", \"optim\", \"ram\", \"expect\", \"imag\", \"bring\", \"percent\", \"amp\", \"live\", \"drive\", \"block\", \"requir\", \"wireless\", \"tactic\", \"gbgb\", \"pros\", \"lag\", \"storag\", \"flagship\", \"headphon\", \"amaz\", \"averag\", \"build\", \"provid\", \"android\", \"sinc\", \"disappoint\", \"buy\", \"app\", \"camera\", \"want\", \"use\", \"display\", \"devic\", \"plus\", \"phone\", \"batteri\", \"good\", \"perform\", \"nord\", \"problem\", \"great\", \"realli\", \"charg\", \"thing\", \"better\", \"photo\", \"issu\", \"oneplus\", \"qualiti\", \"price\", \"time\", \"mobil\", \"servic\", \"renew\", \"return\", \"item\", \"replac\", \"defect\", \"amazon\", \"refund\", \"scratch\", \"center\", \"cheat\", \"second\", \"request\", \"report\", \"said\", \"west\", \"accept\", \"duplic\", \"deliveri\", \"custom\", \"abl\", \"audio\", \"dont\", \"new\", \"eas\", \"messag\", \"pnzz\", \"repair\", \"contact\", \"board\", \"nice\", \"care\", \"help\", \"condit\", \"product\", \"box\", \"bad\", \"purchas\", \"worst\", \"respons\", \"got\", \"like\", \"buy\", \"mobil\", \"phone\", \"plus\", \"need\", \"money\", \"worth\", \"experi\"], \"Freq\": [212.0, 81.0, 50.0, 34.0, 32.0, 37.0, 18.0, 55.0, 17.0, 14.0, 32.0, 150.0, 11.0, 98.0, 15.0, 23.0, 10.0, 67.0, 61.0, 14.0, 12.0, 52.0, 34.0, 14.0, 20.0, 10.0, 23.0, 7.0, 24.0, 49.0, 8.82824234538327, 8.828242341098964, 19.057640199812596, 4.52499334754789, 4.522556862057281, 4.520713320290977, 11.201910780213728, 4.441485992511653, 20.042812235822872, 3.663520302221479, 3.661398432605234, 3.661133634169916, 3.661167935298755, 3.6607988063570023, 3.658337967028439, 3.656650957674259, 3.653192849196858, 3.6532819645265144, 28.497126997216785, 2.8015007128708413, 2.801356205233184, 2.798671327404319, 2.7983904121886285, 2.796688648087713, 2.7763202461404135, 2.7750192179014297, 9.688522104512671, 5.385383458385245, 5.357121286636349, 1.9395393729944477, 46.69452384823745, 38.99164897687902, 16.190354310393552, 15.448858579560971, 37.66436804223327, 9.3384352576002, 9.856593052579866, 8.7538283321487, 31.390132789812633, 18.269283361184623, 113.8030348171458, 11.763052798168461, 8.599333853616782, 7.0074810887017875, 38.228034173099864, 64.0560501342981, 23.213169529145848, 10.033419813160135, 19.90703572493646, 31.543281478073613, 8.457056050867951, 11.891250814838628, 9.45812921502585, 21.315614209099795, 16.457914338889477, 14.612963859607424, 19.371394602688078, 16.15749174167695, 18.87411371442934, 18.052529571602683, 25.69945103904978, 13.523486502530401, 17.962154313045577, 12.357736151244726, 12.437012507136894, 12.787664194013312, 35.48327199844503, 6.928195225627464, 6.923715288734561, 5.248660327395057, 5.241497222118222, 3.56643968477745, 3.564545878804644, 3.5578400614703587, 3.55263017960903, 2.729296099339744, 2.7292714942804985, 2.729258302712582, 2.7288840298358457, 2.72881461362117, 2.7276577282643775, 2.726946983081742, 2.7209190281413913, 2.7088159785623294, 2.6990506536684653, 6.760552594707181, 2.6843700147085463, 5.315697528342267, 43.45290842621398, 164.35868554737968, 2.5335848073844605, 3.1555746497866806, 1.8894880185470835, 1.8894293632793822, 1.88770476014324, 1.8877040825459104, 8.827399925963634, 18.69967194826108, 7.687924147743006, 7.6084466905645645, 12.986407236774445, 6.883921480348057, 15.186656424319787, 48.31429062535903, 19.041279525944976, 16.419160325550614, 12.852615206952086, 12.849993440699512, 6.096798451291358, 8.758998065072296, 9.983264066977382, 66.61961764302036, 46.10201249894168, 28.37389469032711, 19.641904080204185, 19.805354686065623, 10.362635591424617, 8.078660327951164, 8.59067371452846, 18.07752731340401, 14.050122456386486, 17.56575093954426, 13.835161994910393, 9.032801010734559, 9.539354782898812, 9.376966283830514, 9.325073668103073, 9.128440382301578, 8.959994024598911, 9.622657313303401, 5.34660641113524, 4.491109823998394, 4.490331040219406, 4.488898890031218, 4.485885521151458, 3.6352235335196945, 3.6334759494299593, 3.6319712345405297, 2.7807256223413876, 2.780723051346405, 2.7782472828439255, 2.7776645460020553, 2.7767809346553887, 2.7742548821812063, 2.760207715747415, 5.3440578719864895, 11.144956429960066, 4.501838933952816, 1.925118748431212, 1.9251171848845405, 1.925114376427742, 1.9251127378623742, 1.9251102584975117, 1.925110060628046, 1.9251084926321875, 1.9251083083575746, 1.9251078743631276, 1.9251060686558317, 1.9251027325966084, 4.494583503405752, 23.848637799701958, 6.108025412867562, 5.364943454139951, 15.901211878423247, 9.489678111983471, 3.6370558542548665, 3.5160594645776695, 5.580310245709576, 6.206587865938627, 7.953711759010632, 26.780110315390456, 9.393173491227088, 39.818401854130116, 6.228384582390746, 22.122378685307286, 16.190560558196918, 9.333675006150369, 16.19401119873875, 43.94395778224077, 24.301657302372018, 35.24832912320185, 10.962337540361089, 14.122734486869481, 12.08846761643643, 12.574520337837631, 10.50684321951016, 10.50465487404765, 7.938696077697968, 10.25167959511285, 7.110073315433079, 11.570241916850257, 9.710950625156057, 11.648351982443783, 9.785602822264734, 6.5957186280935876, 6.713484727563543, 18.152653748373115, 13.446679551356965, 16.331685680160806, 11.116786377873241, 10.3512650793953, 7.2249840326198544, 31.600835757362606, 6.444283067349337, 5.665252520411452, 5.664824407195824, 4.098522322865231, 4.096546776436227, 3.3192330743672427, 3.316436868341531, 4.613988619331317, 2.5403414432941176, 2.5391416117771866, 2.5347300709939833, 4.289015875137412, 11.500515944884437, 3.6151299133076744, 2.412648745830157, 4.744247501045685, 7.713003138163766, 1.7587384142638591, 1.7587384142638591, 1.7580348085314805, 1.7565465521063268, 1.7564062114018564, 1.7553665868226154, 35.5296438422094, 9.132167234568165, 4.6057850659799575, 4.015461930032141, 51.157565176450795, 9.811956342827003, 20.808668374213248, 9.038990217778633, 12.778713226938812, 5.294053764232714, 6.4572454011726235, 12.361877865045862, 14.280931588936067, 10.949934700039556, 20.553389715185844, 8.316686317670928, 5.085131085754498, 6.273610895518492, 5.317536021097445, 4.8502724214328214], \"Total\": [212.0, 81.0, 50.0, 34.0, 32.0, 37.0, 18.0, 55.0, 17.0, 14.0, 32.0, 150.0, 11.0, 98.0, 15.0, 23.0, 10.0, 67.0, 61.0, 14.0, 12.0, 52.0, 34.0, 14.0, 20.0, 10.0, 23.0, 7.0, 24.0, 49.0, 9.454433760072416, 9.454433759673996, 20.635813657130424, 5.144841887966211, 5.144811109087704, 5.144441805658237, 12.83350001910628, 5.14268991928774, 23.22677922333974, 4.282870427726293, 4.282675763690862, 4.282650208136329, 4.282808819755721, 4.282638247161944, 4.282688957840424, 4.282692345550384, 4.281907463309809, 4.282429822569866, 34.384004478930756, 3.4208489907532242, 3.4208416351192805, 3.420615143876823, 3.420764265418777, 3.4204010195431445, 3.41912504153347, 3.4201616815434126, 12.028076298962306, 6.8624281231322595, 6.859754387305677, 2.558829832025831, 61.7186058028419, 53.700645649573104, 22.290059883238122, 21.48254844594509, 58.16534837768019, 12.845972291096201, 13.710924831240131, 12.020882585240765, 52.18733961131546, 28.27531825971645, 244.91999995759278, 17.107533768299223, 11.983323097486608, 9.42595018677622, 78.44725084665083, 150.17633201744286, 43.64583102985229, 15.25498765105747, 39.29699172286173, 73.32682073984923, 12.820067584904614, 21.270245430073913, 15.200952351193262, 51.10339007321111, 35.87026045598185, 30.79689375998729, 49.32059672219755, 37.57598730115817, 50.55584197158649, 48.609447523090275, 98.51294124906282, 28.73797928088772, 67.08085302056377, 24.76414505274048, 26.918684784517943, 212.59326868816868, 37.81682981186848, 7.553079576661565, 7.553102843044298, 5.873506837344625, 5.873233211472279, 4.193879624710843, 4.194016387435946, 4.193239545401699, 4.193068862539755, 3.3541464042170075, 3.3541459822905644, 3.35414569401707, 3.3541377997079174, 3.3541577233479583, 3.3541890435537725, 3.354098533201852, 3.3538941556614934, 3.3536567128904786, 3.354934656703072, 8.416993359539985, 3.3510636785254095, 6.733690041836416, 55.06021014748047, 212.59326868816868, 3.3406169671149333, 4.165350383877072, 2.5143592217814765, 2.5143580364597695, 2.5142373164053806, 2.5142367403802477, 11.812882376926066, 27.04625037865586, 10.972911335213434, 10.981183416363866, 20.218112062384925, 10.131505772271018, 25.401658759647297, 98.51294124906282, 33.87767498987166, 28.642310623960924, 22.050524613399627, 23.73948588777846, 9.292625905361307, 15.262759386046605, 18.646004645208308, 244.91999995759278, 150.17633201744286, 78.44725084665083, 49.02204015875312, 51.10339007321111, 20.712042399616, 14.41877000841133, 16.964368162256665, 73.32682073984923, 48.609447523090275, 81.3283328541132, 49.32059672219755, 20.407224821295348, 31.428046133373662, 32.08264937491418, 39.29699172286173, 37.57598730115817, 35.87026045598185, 10.246438930915264, 5.968432433148213, 5.1127680630801, 5.112806763561286, 5.112699625457897, 5.112765044450414, 4.257208457274589, 4.2572134049558095, 4.257144630514149, 3.4016184095668502, 3.4016182973113382, 3.4015227938132457, 3.401635621555448, 3.4014479757436504, 3.4016628082736733, 3.4016135879104383, 6.830242425687278, 14.497607499424047, 5.95275190116262, 2.546007704455159, 2.5460076268182408, 2.5460075316789186, 2.546007436758192, 2.5460073434684105, 2.546007300124187, 2.5460072562503298, 2.546007242321177, 2.546007213721787, 2.5460071120506877, 2.5460069582929434, 5.974799127345509, 32.47537826150757, 8.526591623028096, 7.5920943696401, 24.722687049733562, 14.520509969532625, 5.119245192760082, 5.028569836461761, 8.529023265988105, 10.271141005226703, 14.413964081249143, 67.08085302056377, 18.587274520340113, 150.17633201744286, 11.019022616758553, 73.32682073984923, 48.609447523090275, 21.374353152981854, 50.55584197158649, 244.91999995759278, 98.51294124906282, 212.59326868816868, 30.79689375998729, 49.32059672219755, 37.57598730115817, 43.64583102985229, 31.428046133373662, 33.87767498987166, 18.757533864319633, 35.87026045598185, 15.348113062477948, 58.16534837768019, 39.29699172286173, 78.44725084665083, 51.10339007321111, 20.331030309932082, 52.18733961131546, 18.8162034810598, 14.127015763510837, 17.27598586849631, 11.780675723604041, 10.997836240014356, 7.8708739841685755, 34.65703925296505, 7.08903275036507, 6.307076188624791, 6.307087309959363, 4.743930767397779, 4.744128969628024, 3.961975301992987, 3.962292198096056, 5.54552327263214, 3.1799850128627094, 3.1800715672328908, 3.180526757531033, 5.569494152639285, 15.174121280097566, 4.779769944516136, 3.192055854108461, 6.396514340621568, 10.404315410029852, 2.398251342442076, 2.398251342442076, 2.3983005257318384, 2.398410448072684, 2.3984901062119075, 2.398597683086464, 50.42057601689321, 12.824080771966779, 6.406653608308545, 5.590075406341979, 81.3283328541132, 14.451136519993888, 32.08264937491418, 14.56582176336917, 23.522476104632695, 8.034403914237085, 13.037027002676407, 49.02204015875312, 67.08085302056377, 52.18733961131546, 244.91999995759278, 50.55584197158649, 14.886133720108734, 55.06021014748047, 20.712042399616, 26.918684784517943], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.4796, -5.4796, -4.7101, -6.1479, -6.1485, -6.1489, -5.2414, -6.1665, -4.6597, -6.3591, -6.3597, -6.3598, -6.3597, -6.3598, -6.3605, -6.361, -6.3619, -6.3619, -4.3077, -6.6274, -6.6274, -6.6284, -6.6285, -6.6291, -6.6364, -6.6369, -5.3866, -5.9738, -5.9791, -6.9951, -3.8139, -3.9942, -4.8731, -4.92, -4.0288, -5.4234, -5.3694, -5.488, -4.211, -4.7523, -2.9231, -5.1926, -5.5058, -5.7105, -4.014, -3.4978, -4.5128, -5.3516, -4.6665, -4.2062, -5.5225, -5.1817, -5.4107, -4.5981, -4.8567, -4.9756, -4.6937, -4.8751, -4.7197, -4.7642, -4.4111, -5.0531, -4.7693, -5.1432, -5.1369, -5.109, -3.9245, -5.5579, -5.5586, -5.8355, -5.8369, -6.222, -6.2225, -6.2244, -6.2258, -6.4895, -6.4895, -6.4895, -6.4896, -6.4897, -6.4901, -6.4903, -6.4926, -6.497, -6.5006, -5.5824, -6.5061, -5.8229, -3.7218, -2.3915, -6.5639, -6.3444, -6.8572, -6.8572, -6.8582, -6.8582, -5.3157, -4.565, -5.4539, -5.4643, -4.9296, -5.5643, -4.7731, -3.6158, -4.5469, -4.6951, -4.94, -4.9402, -5.6858, -5.3234, -5.1926, -3.2945, -3.6627, -4.1481, -4.5159, -4.5076, -5.1553, -5.4043, -5.3428, -4.5989, -4.8509, -4.6276, -4.8663, -5.2927, -5.2381, -5.2553, -5.2608, -5.2821, -5.3008, -5.0302, -5.6179, -5.7922, -5.7924, -5.7927, -5.7934, -6.0036, -6.0041, -6.0045, -6.2716, -6.2716, -6.2725, -6.2727, -6.273, -6.2739, -6.279, -5.6183, -4.8833, -5.7898, -6.6393, -6.6393, -6.6393, -6.6393, -6.6393, -6.6393, -6.6393, -6.6393, -6.6393, -6.6393, -6.6393, -5.7914, -4.1226, -5.4847, -5.6144, -4.5279, -5.0441, -6.0031, -6.037, -5.5751, -5.4687, -5.2207, -4.0067, -5.0543, -3.61, -5.4652, -4.1977, -4.5099, -5.0607, -4.5097, -3.5114, -4.1038, -3.7319, -4.8999, -4.6465, -4.8021, -4.7626, -4.9423, -4.9425, -5.2226, -4.9669, -5.3328, -4.8459, -5.0211, -4.8392, -5.0134, -5.4079, -5.3902, -3.8949, -4.195, -4.0006, -4.3852, -4.4566, -4.8161, -3.3405, -4.9305, -5.0593, -5.0594, -5.3831, -5.3835, -5.594, -5.5948, -5.2646, -5.8614, -5.8619, -5.8636, -5.3376, -4.3513, -5.5086, -5.913, -5.2368, -4.7508, -6.2291, -6.2291, -6.2295, -6.2303, -6.2304, -6.231, -3.2233, -4.5819, -5.2664, -5.4035, -2.8588, -4.5101, -3.7583, -4.5921, -4.2459, -5.1271, -4.9285, -4.2791, -4.1348, -4.4004, -3.7707, -4.6754, -5.1674, -4.9573, -5.1227, -5.2147], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0186, 1.0186, 1.0076, 0.9587, 0.9582, 0.9579, 0.9511, 0.9405, 0.9397, 0.9309, 0.9304, 0.9303, 0.9303, 0.9302, 0.9295, 0.9291, 0.9283, 0.9282, 0.8993, 0.8874, 0.8873, 0.8864, 0.8863, 0.8858, 0.8789, 0.8781, 0.8708, 0.8447, 0.8399, 0.81, 0.8082, 0.767, 0.7674, 0.7574, 0.6525, 0.7682, 0.7571, 0.77, 0.5788, 0.6504, 0.3207, 0.7126, 0.7553, 0.7906, 0.3683, 0.2351, 0.4557, 0.6681, 0.407, 0.2436, 0.6711, 0.5056, 0.6126, 0.2127, 0.308, 0.3416, 0.1526, 0.2431, 0.1018, 0.0966, -0.2566, 0.3333, -0.2305, 0.392, 0.315, -1.7238, 1.1874, 1.1648, 1.1641, 1.1386, 1.1373, 1.0891, 1.0885, 1.0868, 1.0854, 1.045, 1.045, 1.045, 1.0448, 1.0448, 1.0444, 1.0441, 1.042, 1.0376, 1.0336, 1.032, 1.0293, 1.0147, 1.0144, 0.9938, 0.9746, 0.9735, 0.9654, 0.9654, 0.9645, 0.9645, 0.9598, 0.8821, 0.8953, 0.8842, 0.8084, 0.8647, 0.7367, 0.5387, 0.675, 0.6947, 0.7113, 0.6373, 0.8297, 0.6958, 0.6264, -0.0508, 0.0702, 0.2342, 0.3365, 0.3032, 0.5586, 0.6718, 0.5707, -0.1491, 0.0099, -0.2814, -0.02, 0.4361, 0.0589, 0.0211, -0.1873, -0.1638, -0.136, 1.3875, 1.3403, 1.3207, 1.3205, 1.3202, 1.3195, 1.2924, 1.2919, 1.2915, 1.2488, 1.2488, 1.2479, 1.2477, 1.2474, 1.2464, 1.2414, 1.205, 1.1873, 1.171, 1.1708, 1.1708, 1.1708, 1.1708, 1.1708, 1.1708, 1.1708, 1.1708, 1.1708, 1.1708, 1.1708, 1.1657, 1.1416, 1.1167, 1.1031, 1.009, 1.025, 1.1085, 1.0925, 1.0261, 0.9466, 0.8558, 0.5321, 0.7678, 0.1228, 0.8798, 0.252, 0.3509, 0.6218, 0.3119, -0.2677, 0.0507, -0.3466, 0.4174, 0.1998, 0.3162, 0.2059, 0.3547, 0.2794, 0.5905, 0.1979, 0.6808, -0.1645, 0.0524, -0.4569, -0.2026, 0.3246, -0.6004, 1.9151, 1.9016, 1.8947, 1.893, 1.8904, 1.8653, 1.8586, 1.8556, 1.8436, 1.8436, 1.8047, 1.8042, 1.774, 1.773, 1.7671, 1.7264, 1.7259, 1.724, 1.6897, 1.6738, 1.6717, 1.671, 1.6521, 1.6516, 1.6408, 1.6408, 1.6404, 1.6395, 1.6394, 1.6388, 1.6009, 1.6114, 1.6209, 1.6201, 1.4874, 1.5638, 1.518, 1.4738, 1.3408, 1.5338, 1.2484, 0.5733, 0.404, 0.3895, -0.5269, 0.1461, 0.8768, -0.2211, 0.5913, 0.2372]}, \"token.table\": {\"Topic\": [2, 4, 4, 3, 1, 2, 3, 1, 2, 4, 3, 1, 2, 3, 1, 2, 3, 4, 2, 4, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 2, 3, 4, 1, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 2, 3, 4, 3, 1, 1, 3, 1, 3, 2, 1, 2, 3, 4, 1, 2, 3, 2, 3, 4, 4, 1, 2, 3, 2, 4, 3, 2, 2, 3, 2, 1, 2, 3, 1, 2, 4, 4, 1, 3, 4, 2, 1, 2, 3, 3, 4, 2, 2, 4, 2, 1, 2, 3, 1, 2, 3, 4, 2, 1, 2, 3, 1, 4, 3, 2, 4, 4, 2, 1, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 1, 2, 3, 3, 1, 2, 3, 2, 1, 2, 3, 4, 1, 2, 3, 2, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 3, 4, 1, 1, 2, 3, 1, 1, 2, 3, 4, 4, 1, 3, 2, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 1, 1, 2, 3, 4, 3, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 2, 1, 3, 3, 3, 1, 2, 3, 4, 2, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 1, 2, 3, 4, 4, 1, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 4, 3, 3, 4, 1, 3, 4, 1, 2, 3, 1, 3, 1, 2, 1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 3, 1, 2, 4, 4, 4, 4, 1, 2, 3, 4, 1, 4, 1, 1, 2, 3, 1, 4, 1, 3, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 1, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 4, 3, 1, 1, 1, 2, 3, 1, 2, 3, 4, 1, 1, 2, 1, 2, 3, 4, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 3, 1, 2, 3, 4, 2, 3, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3], \"Freq\": [0.20921509018385018, 0.8368603607354007, 0.9433749953654099, 0.8819286760138658, 0.12134603305720894, 0.20224338842868156, 0.647178842971781, 0.057708334096337785, 0.028854167048168892, 0.9233333455414046, 0.7855436306117823, 0.23449343935730205, 0.11724671967865102, 0.7034803180719061, 0.2690012456925024, 0.053800249138500476, 0.48420224224650427, 0.16140074741550142, 0.8980377066667714, 0.626555452476128, 0.7288890706134834, 0.14577781412269666, 0.20660431391836037, 0.13773620927890692, 0.6198129417550812, 0.814332141480419, 0.05816658153431564, 0.11633316306863128, 0.1485069841033668, 0.742534920516834, 0.2805254608130091, 0.062338991291779805, 0.6545594085636879, 0.9340491650134313, 0.2639247155789021, 0.4872456287610501, 0.24362281438052505, 0.7615207665276819, 0.1458231255053008, 0.09721541700353387, 0.016202569500588977, 0.44605196049898727, 0.25090422778068033, 0.278782475311867, 0.2539600331465128, 0.7618800994395383, 0.7855437020555461, 0.8338205335987997, 0.06919870963895806, 0.2075961289168742, 0.6919870963895807, 0.7855435773035088, 0.9519343229214253, 0.7486971057391574, 0.24956570191305244, 0.19534129785661664, 0.7813651914264665, 0.795431290276398, 0.2683329026016122, 0.11925906782293876, 0.4024993539024183, 0.2087033686901428, 0.4261656889620027, 0.3063065889414394, 0.2663535556012517, 0.9537708179394371, 0.23393489586855604, 0.701804687605668, 0.9513107564763771, 0.11807185709160598, 0.5608413211851283, 0.3246976070019164, 0.8944039709883173, 0.843182625574898, 0.8819216274767941, 0.8513198471726648, 0.9539164067997009, 0.7823550668931123, 0.9537397164166639, 0.1974040231486432, 0.6909140810202512, 0.0987020115743216, 0.877090137343224, 0.1788884634481841, 0.7155538537927364, 0.833857932046562, 0.0659016744061222, 0.1318033488122444, 0.7908200928734664, 0.8942051953250649, 0.18486850968243124, 0.7025003367932386, 0.11092110580945874, 0.7823655393488439, 0.8893548561544441, 0.8944826105904066, 0.17954951968593372, 0.7181980787437349, 0.9267742950344998, 0.421065373795625, 0.14035512459854166, 0.421065373795625, 0.20813150241595538, 0.20813150241595538, 0.555017339775881, 0.06937716747198512, 0.8944176355131396, 0.37029838677861354, 0.28800985638336607, 0.32915412158098983, 0.15633514547906524, 0.7816757273953263, 0.7855436886821434, 0.8944154535430457, 0.9432399815208058, 0.8339409488095825, 0.8944123226875405, 0.7816072702328141, 0.23578832773150005, 0.5305237373958751, 0.23578832773150005, 0.6365976090760546, 0.14146613535023436, 0.21219920302535153, 0.9340010987590488, 0.7823555288036851, 0.06897689843236048, 0.13795379686472095, 0.7587458827559652, 0.4457870098802784, 0.185744587450116, 0.185744587450116, 0.185744587450116, 0.6240216712601303, 0.2340081267225489, 0.07800270890751629, 0.2527434683448185, 0.54761084808044, 0.21061955695401538, 0.8769970004444998, 0.21452316869544108, 0.5363079217386028, 0.21452316869544108, 0.7293454032520953, 0.14586908065041906, 0.14586908065041906, 0.11728015650465319, 0.11728015650465319, 0.7036809390279192, 0.9339926479314127, 0.85128018719741, 0.8769771652686851, 0.39201802646148337, 0.4410202797691688, 0.14700675992305626, 0.7855437600836452, 0.06114963131343716, 0.7714261181079766, 0.1646336227669462, 0.8944153410322948, 0.0767046044926276, 0.2301138134778828, 0.2301138134778828, 0.4602276269557656, 0.5269690015586773, 0.18329356575953995, 0.29785204435925244, 0.7202275255431516, 0.24007584184771721, 0.592068167314103, 0.13157070384757846, 0.06578535192378923, 0.13157070384757846, 0.13171596022289755, 0.6585798011144878, 0.13171596022289755, 0.5641683843964136, 0.1410420960991034, 0.18805612813213787, 0.09402806406606894, 0.15608772709408514, 0.7804386354704257, 0.8771515148506644, 0.9519343229615408, 0.16798953099400832, 0.8399476549700416, 0.9340037073294143, 0.6533099355523116, 0.12034656707542583, 0.20630840070073, 0.03438473345012167, 0.9337325173937298, 0.1673696435120625, 0.66947857404825, 0.8944281064802749, 0.20948030620758154, 0.5586141498868841, 0.13965353747172102, 0.06982676873586051, 0.22438886599532715, 0.4079797563551403, 0.12239392690654208, 0.24478785381308416, 0.7954700398250979, 0.1822670336888399, 0.7290681347553596, 0.09113351684441995, 0.7855436598985671, 0.19683753912728436, 0.590512617381853, 0.15747003130182746, 0.393113712156484, 0.5896705682347261, 0.975948821578225, 0.8339409488095825, 0.5940138016400909, 0.05748520661033138, 0.1341321487574399, 0.21077909090454838, 0.7809632379684562, 0.09080967883354142, 0.10897161460024972, 0.9207293841517517, 0.04845944127114482, 0.8770352330838042, 0.20152983013631606, 0.20152983013631606, 0.26870644018175477, 0.33588305022719345, 0.8819331676253094, 0.19222792862200067, 0.09611396431100033, 0.7689117144880027, 0.05949951858929304, 0.15866538290478144, 0.05949951858929304, 0.7139942230715164, 0.38523459290282136, 0.2838570684547105, 0.2838570684547105, 0.040551009779244356, 0.9395828370031825, 0.5089448103571917, 0.2290251646607363, 0.2544724051785959, 0.7954316652595791, 0.8610750465093642, 0.12916125697640463, 0.881934388627268, 0.9395817450315298, 0.14838180690379063, 0.642987829916426, 0.14838180690379063, 0.04946060230126354, 0.8945459409929689, 0.9267714402229206, 0.7855436012575542, 0.831388141498797, 0.1662776282997594, 0.4870621081756198, 0.16235403605853993, 0.35717887932878783, 0.46545810885080346, 0.27355871309652485, 0.17965049815294168, 0.08574228320935853, 0.26061835638798725, 0.26061835638798725, 0.45608212367897766, 0.21522441776614679, 0.6456732532984404, 0.10761220888307339, 0.8952381356477563, 0.8819773288886235, 0.1188072696845579, 0.8316508877919053, 0.37582204665246055, 0.1384607540298539, 0.31648172349680886, 0.15824086174840443, 0.8339238467162919, 0.7286050812169119, 0.14572101624338238, 0.8769752795604816, 0.4109316421066242, 0.39136346867297545, 0.19568173433648772, 0.4258038483930094, 0.23951466472106778, 0.31935288629475705, 0.12295837931336924, 0.22132508276406462, 0.024591675862673846, 0.6270877344981831, 0.8571317242859237, 0.07792106584417488, 0.07792106584417488, 0.7855438075239856, 0.7954547973056508, 0.1988636993264127, 0.2059616030414806, 0.13730773536098706, 0.6178848091244418, 0.4844019336545347, 0.3569277405875519, 0.1529690316803794, 0.14640768770361431, 0.7320384385180716, 0.40815355452046226, 0.5895551343073344, 0.31818713634192264, 0.31818713634192264, 0.3500058499761149, 0.03181871363419227, 0.846377807986712, 0.9202226583181251, 0.8338856268772349, 0.9092697674126258, 0.7571374976942759, 0.7571980568609084, 0.7855437155923624, 0.12446474071685454, 0.24892948143370908, 0.6223237035842727, 0.9261410678262282, 0.9016281700007704, 0.9513124339327592, 0.4871602092534997, 0.20878294682292842, 0.20878294682292842, 0.13918863121528563, 0.9339665085092798, 0.8431473987338988, 0.9718529784636967, 0.742630701552018, 0.10609010022171687, 0.10609010022171687, 0.9341631117147261, 0.9566223079017303, 0.38944066661771165, 0.5841609999265674, 0.8377409070144425, 0.41612426000968467, 0.5548323466795796, 0.7014453493136669, 0.23381511643788894, 0.058453779109472234, 0.7006087041179498, 0.1556908231373222, 0.0778454115686611, 0.9339530736454094, 0.7823491449956209, 0.9339919091213511, 0.9339955253938607, 0.15396279482066577, 0.09237767689239947, 0.7390214151391957, 0.6982411811030411, 0.27929647244121647, 0.7510437569598426, 0.1668986126577428, 0.0834493063288714, 0.655523310063565, 0.13110466201271298, 0.06555233100635649, 0.13110466201271298, 0.7855437287140965, 0.9719227447573867, 0.8774174572610853, 0.3198714736915993, 0.2665595614096661, 0.42649529825546567, 0.3443012918327298, 0.29511539299948264, 0.3443012918327298, 0.09837179766649422, 0.9718471643793376, 0.7778030685843874, 0.7954698575786837, 0.4364023924278733, 0.24547634574067873, 0.3000266447941629, 0.027275149526742083, 0.9255138565056439, 0.052886506086036796, 0.48457154383660184, 0.24228577191830092, 0.24228577191830092, 0.7178087490034885, 0.1345891404381541, 0.1345891404381541, 0.8819331385209692, 0.3630086024069413, 0.544512903610412, 0.2731945990019145, 0.7285189306717721, 0.9395969240342458, 0.9434006726023272, 0.8944155304139667, 0.7855437198900558, 0.9539552368756441, 0.7262482513617605, 0.11173050020950162, 0.09310875017458468, 0.07448700013966775, 0.12753759368934622, 0.21256265614891037, 0.12753759368934622, 0.5526629059871669, 0.14484327243631076, 0.4828109081210359, 0.09656218162420718, 0.24140545406051794, 0.8819579293887011], \"Term\": [\"abl\", \"abl\", \"accept\", \"afford\", \"amaz\", \"amaz\", \"amaz\", \"amazon\", \"amazon\", \"amazon\", \"amp\", \"android\", \"android\", \"android\", \"app\", \"app\", \"app\", \"app\", \"arrang\", \"audio\", \"automat\", \"automat\", \"averag\", \"averag\", \"averag\", \"awesom\", \"awesom\", \"awesom\", \"backup\", \"backup\", \"bad\", \"bad\", \"bad\", \"base\", \"batteri\", \"batteri\", \"batteri\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"bit\", \"bit\", \"block\", \"board\", \"box\", \"box\", \"box\", \"bring\", \"browser\", \"budget\", \"budget\", \"build\", \"build\", \"busi\", \"buy\", \"buy\", \"buy\", \"buy\", \"camera\", \"camera\", \"camera\", \"capac\", \"care\", \"care\", \"center\", \"charg\", \"charg\", \"charg\", \"cheap\", \"cheat\", \"chrome\", \"clear\", \"close\", \"cloud\", \"colour\", \"come\", \"come\", \"come\", \"compromis\", \"condit\", \"condit\", \"contact\", \"custom\", \"custom\", \"custom\", \"data\", \"day\", \"day\", \"day\", \"deal\", \"defect\", \"definit\", \"deliveri\", \"deliveri\", \"design\", \"devic\", \"devic\", \"devic\", \"disappoint\", \"disappoint\", \"disappoint\", \"disappoint\", \"dislik\", \"display\", \"display\", \"display\", \"dont\", \"dont\", \"drive\", \"drop\", \"duplic\", \"eas\", \"easi\", \"easili\", \"everyth\", \"everyth\", \"everyth\", \"excel\", \"excel\", \"excel\", \"exchang\", \"expand\", \"expect\", \"expect\", \"expect\", \"experi\", \"experi\", \"experi\", \"experi\", \"face\", \"face\", \"face\", \"fast\", \"fast\", \"fast\", \"faster\", \"feel\", \"feel\", \"feel\", \"fine\", \"fine\", \"fine\", \"flagship\", \"flagship\", \"flagship\", \"font\", \"fps\", \"function\", \"game\", \"game\", \"game\", \"gbgb\", \"good\", \"good\", \"good\", \"gorilla\", \"got\", \"got\", \"got\", \"got\", \"great\", \"great\", \"great\", \"hai\", \"hai\", \"hang\", \"hang\", \"hang\", \"hang\", \"headphon\", \"headphon\", \"headphon\", \"heat\", \"heat\", \"heat\", \"heat\", \"help\", \"help\", \"hrtz\", \"html\", \"imag\", \"imag\", \"internet\", \"issu\", \"issu\", \"issu\", \"issu\", \"item\", \"lag\", \"lag\", \"level\", \"life\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"like\", \"line\", \"littl\", \"littl\", \"littl\", \"live\", \"look\", \"look\", \"look\", \"love\", \"love\", \"memori\", \"messag\", \"mobil\", \"mobil\", \"mobil\", \"mobil\", \"money\", \"money\", \"money\", \"month\", \"month\", \"motion\", \"need\", \"need\", \"need\", \"need\", \"netflix\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nord\", \"nord\", \"nord\", \"nord\", \"notch\", \"oneplus\", \"oneplus\", \"oneplus\", \"oper\", \"oplus\", \"oplus\", \"optim\", \"outstand\", \"overal\", \"overal\", \"overal\", \"overal\", \"pack\", \"packag\", \"percent\", \"perfect\", \"perfect\", \"perform\", \"perform\", \"perform\", \"phone\", \"phone\", \"phone\", \"phone\", \"photo\", \"photo\", \"photo\", \"pictur\", \"pictur\", \"pictur\", \"piec\", \"pixel\", \"play\", \"play\", \"plus\", \"plus\", \"plus\", \"plus\", \"pnzz\", \"point\", \"point\", \"present\", \"price\", \"price\", \"price\", \"problem\", \"problem\", \"problem\", \"product\", \"product\", \"product\", \"product\", \"proper\", \"proper\", \"proper\", \"pros\", \"provid\", \"provid\", \"purchas\", \"purchas\", \"purchas\", \"qualiti\", \"qualiti\", \"qualiti\", \"ram\", \"ram\", \"rang\", \"rang\", \"realli\", \"realli\", \"realli\", \"realli\", \"refund\", \"renew\", \"repair\", \"replac\", \"report\", \"request\", \"requir\", \"respons\", \"respons\", \"respons\", \"return\", \"said\", \"scratch\", \"screen\", \"screen\", \"screen\", \"screen\", \"scroll\", \"second\", \"segment\", \"selfi\", \"selfi\", \"selfi\", \"sell\", \"servic\", \"sinc\", \"sinc\", \"small\", \"smartphon\", \"smartphon\", \"smooth\", \"smooth\", \"smooth\", \"softwar\", \"softwar\", \"softwar\", \"soo\", \"space\", \"special\", \"start\", \"storag\", \"storag\", \"storag\", \"super\", \"super\", \"superb\", \"superb\", \"superb\", \"support\", \"support\", \"support\", \"support\", \"tactic\", \"team\", \"temperatur\", \"thing\", \"thing\", \"thing\", \"time\", \"time\", \"time\", \"time\", \"touch\", \"trust\", \"upgrad\", \"use\", \"use\", \"use\", \"use\", \"valu\", \"valu\", \"variant\", \"variant\", \"variant\", \"video\", \"video\", \"video\", \"visibl\", \"want\", \"want\", \"wast\", \"wast\", \"weight\", \"west\", \"wide\", \"wireless\", \"wonder\", \"work\", \"work\", \"work\", \"work\", \"worst\", \"worst\", \"worst\", \"worst\", \"worth\", \"worth\", \"worth\", \"worth\", \"zero\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 4, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el2678412573632258002645067259\", ldavis_el2678412573632258002645067259_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el2678412573632258002645067259\", ldavis_el2678412573632258002645067259_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el2678412573632258002645067259\", ldavis_el2678412573632258002645067259_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "1      0.083444 -0.079995       1        1  33.718636\n",
              "2      0.072067  0.111518       2        1  28.618269\n",
              "3      0.062112 -0.029392       3        1  23.449330\n",
              "0     -0.217623 -0.002132       4        1  14.213766, topic_info=         Term        Freq       Total Category  logprob  loglift\n",
              "431      good  212.000000  212.000000  Default  30.0000  30.0000\n",
              "796   product   81.000000   81.000000  Default  29.0000  29.0000\n",
              "667      nice   50.000000   50.000000  Default  28.0000  28.0000\n",
              "31     amazon   34.000000   34.000000  Default  27.0000  27.0000\n",
              "76        bad   32.000000   32.000000  Default  26.0000  26.0000\n",
              "...       ...         ...         ...      ...      ...      ...\n",
              "761      plus    8.316686   50.555842   Topic4  -4.6754   0.1461\n",
              "658      need    5.085131   14.886134   Topic4  -5.1674   0.8768\n",
              "640     money    6.273611   55.060210   Topic4  -4.9573  -0.2211\n",
              "1166    worth    5.317536   20.712042   Topic4  -5.1227   0.5913\n",
              "351    experi    4.850272   26.918685   Topic4  -5.2147   0.2372\n",
              "\n",
              "[276 rows x 6 columns], token_table=      Topic      Freq    Term\n",
              "term                         \n",
              "3         2  0.209215     abl\n",
              "3         4  0.836860     abl\n",
              "5         4  0.943375  accept\n",
              "22        3  0.881929  afford\n",
              "30        1  0.121346    amaz\n",
              "...     ...       ...     ...\n",
              "1166      1  0.144843   worth\n",
              "1166      2  0.482811   worth\n",
              "1166      3  0.096562   worth\n",
              "1166      4  0.241405   worth\n",
              "1178      3  0.881958    zero\n",
              "\n",
              "[414 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 4, 1])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#---------------------LDAModel,BOW/TFIDF Object,CountVectorizerObject ----------\n",
        "\n",
        "pyLDAvis.sklearn.prepare(lda_tf,tfObject,tf_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTP5WjzG07JI",
        "outputId": "273d36db-787c-4879-c54d-dacdae9e63f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vikas\\anaconda3\\envs\\Python_3_7\\lib\\site-packages\\pyLDAvis\\_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el2678412573646265046370858989\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el2678412573646265046370858989_data = {\"mdsDat\": {\"x\": [-0.0976452414179114, -0.02349713976441824, 0.03166076054673898, 0.08948162063559055], \"y\": [0.05824956983690957, -0.10524251990437605, 0.017123754629401435, 0.02986919543806507], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [37.03086208529624, 29.000702207547906, 18.65534750130137, 15.31308820585448]}, \"tinfo\": {\"Term\": [\"good\", \"nice\", \"money\", \"bad\", \"valu\", \"best\", \"awesom\", \"like\", \"excel\", \"product\", \"storag\", \"super\", \"amazon\", \"qualiti\", \"servic\", \"worth\", \"work\", \"life\", \"price\", \"amaz\", \"batteri\", \"outstand\", \"oneplus\", \"defect\", \"camera\", \"return\", \"west\", \"day\", \"everi\", \"everyth\", \"awesom\", \"excel\", \"best\", \"super\", \"worth\", \"perfect\", \"amaz\", \"video\", \"smooth\", \"budget\", \"featur\", \"low\", \"oneplus\", \"work\", \"proper\", \"browser\", \"html\", \"support\", \"oxygen\", \"rate\", \"premium\", \"segment\", \"month\", \"note\", \"photo\", \"nord\", \"sim\", \"superb\", \"main\", \"function\", \"price\", \"qualiti\", \"plus\", \"better\", \"phone\", \"camera\", \"buy\", \"mobil\", \"display\", \"batteri\", \"rang\", \"issu\", \"use\", \"love\", \"realli\", \"great\", \"money\", \"valu\", \"good\", \"wast\", \"day\", \"life\", \"wonder\", \"capac\", \"interfac\", \"dislik\", \"job\", \"clear\", \"wow\", \"absolut\", \"product\", \"play\", \"short\", \"audio\", \"user\", \"hang\", \"shot\", \"open\", \"deliveri\", \"speaker\", \"est\", \"urdu\", \"new\", \"proof\", \"damag\", \"nic\", \"mark\", \"item\", \"look\", \"batteri\", \"overal\", \"great\", \"purchas\", \"camera\", \"problem\", \"drain\", \"happi\", \"qualiti\", \"phone\", \"rang\", \"renew\", \"price\", \"charg\", \"like\", \"use\", \"issu\", \"experi\", \"better\", \"storag\", \"bad\", \"outstand\", \"memori\", \"everi\", \"space\", \"brilliant\", \"bed\", \"deal\", \"higher\", \"charger\", \"piec\", \"colour\", \"seal\", \"accessori\", \"aspect\", \"expand\", \"accuraci\", \"clean\", \"boom\", \"rob\", \"simpli\", \"appli\", \"waist\", \"mirag\", \"headphon\", \"qualitynot\", \"thing\", \"pcs\", \"email\", \"everyth\", \"total\", \"warp\", \"condit\", \"charg\", \"poor\", \"want\", \"averag\", \"variant\", \"buy\", \"product\", \"mobil\", \"phone\", \"use\", \"renew\", \"camera\", \"problem\", \"issu\", \"batteri\", \"perform\", \"nice\", \"servic\", \"defect\", \"west\", \"scratch\", \"second\", \"seller\", \"amazon\", \"return\", \"unabl\", \"center\", \"fab\", \"camara\", \"ine\", \"poco\", \"help\", \"cwllotap\", \"fabul\", \"thank\", \"choic\", \"pnzz\", \"upton\", \"frequenc\", \"dead\", \"hype\", \"cover\", \"request\", \"like\", \"batterygood\", \"heart\", \"custom\", \"care\", \"reach\", \"got\", \"expect\", \"replac\", \"need\", \"phone\", \"face\", \"slow\", \"screen\", \"mobil\", \"cost\", \"product\", \"problem\", \"experi\", \"box\", \"worst\"], \"Freq\": [48.0, 17.0, 13.0, 10.0, 10.0, 15.0, 11.0, 9.0, 9.0, 18.0, 4.0, 7.0, 4.0, 15.0, 2.0, 6.0, 10.0, 6.0, 10.0, 6.0, 14.0, 2.0, 6.0, 2.0, 18.0, 2.0, 1.0, 3.0, 2.0, 4.0, 10.926150920864165, 9.084996824287286, 14.845961807142324, 7.568168284793997, 5.856377037400999, 3.2731745458398307, 5.697437169847203, 3.1487660522002345, 2.90793936705584, 3.0105283779285275, 2.745360390324835, 2.341679283772975, 5.667017636453613, 8.523763112398397, 2.5975812619418175, 2.2504103275194973, 2.250410327515791, 2.584439580395249, 2.3452427779799545, 2.207986736567532, 1.9237717029849137, 1.835368232800434, 3.18315460649252, 1.2917692662035938, 2.6752021427787063, 5.580954246894438, 1.7449834544745175, 2.7773783905110103, 1.187882112489152, 1.1796559983460604, 7.5836409225984776, 10.712993730035569, 5.040102016852348, 4.470924587237262, 17.40446738065826, 10.750209052932522, 5.550838598337381, 5.706433083761132, 3.762155514069364, 5.728710500303537, 3.4263615370565628, 3.5609554157614953, 3.671574750417267, 2.7274617521876685, 2.774847696410923, 3.0269124237250815, 13.273701933771411, 10.451343671436806, 46.75324724124225, 2.6502289035526463, 3.140299222515087, 4.803690975215264, 1.4349617246509139, 1.4266986390617888, 1.4928488574695737, 1.2904192667431635, 1.1824807815446587, 1.1147615599910852, 1.106401596781352, 1.089889015188563, 12.746791431174445, 0.9174186751479274, 0.8714264872814277, 0.9054130864877051, 2.298302162453214, 2.6104609782949164, 0.9648619984891672, 1.1070399374226092, 1.2439868704517947, 1.8207950488083315, 0.7225618887324363, 0.7225618767184185, 1.418061932623622, 0.7149330602823661, 0.9807268450802827, 0.6940730347081518, 1.1769992770496933, 1.8953103546437329, 1.794676757985538, 7.4004707095212074, 2.236626236222901, 3.8095059702108305, 1.7581577161103068, 5.900138246914349, 3.045515169605977, 1.9338579702419572, 1.5345646306033924, 4.02731956160164, 5.905329812907396, 2.25231016299667, 1.6844185727220553, 2.4749780199513465, 1.878331982054311, 2.2541906470943225, 1.8380437239331702, 1.7188708344960744, 1.5931182577599505, 1.5438954963877995, 3.961104377544327, 8.720720025326658, 2.0751885017290705, 1.2605734480416748, 1.671547569151769, 1.2276660708032745, 1.1057311308795437, 0.960771127441387, 0.9883691612126011, 0.8978910268106735, 1.089082689549524, 0.8904205588815935, 1.0950526322282306, 0.7232591076306841, 0.6976192189785952, 1.0218977272889682, 0.684839609981286, 0.6690216993320741, 0.647717983746157, 0.6276427047768839, 0.608676110730072, 0.7214948835460153, 0.6255411699969279, 0.5697433636167736, 0.571748194319045, 0.9984126951476603, 0.5510113189875231, 1.7882689883693974, 0.5382894466429365, 0.53023721809853, 2.1010240406533844, 0.9626764059278289, 0.6876087111800364, 1.1527885818195447, 2.1969033853446356, 1.344798805976606, 0.9763106453845815, 1.335279747211256, 1.1615049866910752, 1.9291703676349945, 2.3604050135471133, 1.7849752509797066, 2.665315452136955, 1.4377899556488773, 1.059743582135833, 1.4127017472575916, 1.1415161880508287, 1.1104212489094134, 1.0698769670747887, 0.9852725947878643, 16.977697947243847, 2.1123731148553304, 1.671267623768804, 1.3924864569084305, 1.0373456553240086, 0.8784629373324122, 0.7157241808736582, 3.050493956044881, 1.597081108292394, 0.7794618011348972, 0.6520483714094595, 0.6048091561815172, 0.6022793914529343, 0.5760242406468231, 0.57589733578203, 0.610668033453971, 0.5391630860388563, 0.7947691752363162, 1.0360487008340222, 0.8480462930612453, 0.5238466403851167, 0.5159031681300201, 0.4928051788243266, 0.48998339341471586, 0.5324911624417435, 0.5952711359769056, 0.45725395877522135, 4.947788418547339, 0.45835852254283954, 0.4738125371314626, 0.9925835459167247, 0.838311416307874, 0.5665764365073636, 0.9505898301150627, 1.260012965692914, 1.0162659848812703, 0.9870923886892126, 4.15757585813588, 0.8133387951382863, 0.6981749662016135, 1.0441201016168438, 1.475832992761041, 0.6703664733845177, 1.4268917511456607, 1.0536063137337746, 0.9734927085485517, 0.8139064818193024, 0.7396607437427852], \"Total\": [48.0, 17.0, 13.0, 10.0, 10.0, 15.0, 11.0, 9.0, 9.0, 18.0, 4.0, 7.0, 4.0, 15.0, 2.0, 6.0, 10.0, 6.0, 10.0, 6.0, 14.0, 2.0, 6.0, 2.0, 18.0, 2.0, 1.0, 3.0, 2.0, 4.0, 11.340393822512445, 9.498118455640366, 15.619775158801602, 7.9748151548383275, 6.378445145371545, 3.683320341019482, 6.413938040603656, 3.572319040542241, 3.324407857205247, 3.446245231878367, 3.1753917164812493, 2.7525819245016225, 6.667408257422065, 10.057715214458167, 3.06639034977697, 2.6574187326008456, 2.6574187326001026, 3.096519612759364, 2.824136918289549, 2.6632585786507486, 2.3295265261577396, 2.24086685009282, 3.927073060479527, 1.6969908890957401, 3.5164811787957193, 7.361055624559244, 2.323952620108416, 3.726597508649088, 1.5946732978062887, 1.5845798965357325, 10.339914442049109, 15.312638762718247, 7.085438016954572, 6.279704287901748, 30.132688503838494, 18.190309353317396, 9.119911507330707, 10.305426459961087, 5.940136850540826, 14.326373161275276, 5.940101159935067, 6.612887248682521, 7.6283070632190855, 3.8246565547493487, 4.252481089590551, 7.934884330867117, 13.71213189080851, 10.880081210819743, 48.98598801209722, 3.110436691572113, 3.9404097416042654, 6.202584858881276, 1.8573820617792085, 1.849374037993346, 1.958177747330586, 1.7088593839980921, 1.6114665269637172, 1.533121125689635, 1.534419362462169, 1.5765286907889202, 18.540211773887112, 1.3492120776705607, 1.2928816743087959, 1.3434072156487784, 3.4341520938570422, 3.935305230844591, 1.4667216371390157, 1.6847220015876134, 1.9008430709166368, 2.8007916395656474, 1.1411616812555503, 1.1411616801331141, 2.2422557046454488, 1.1332188803209873, 1.5569357682849447, 1.1125791688579831, 1.9064135177688608, 3.114275964237318, 3.025461774097719, 14.326373161275276, 3.9926129779794075, 7.934884330867117, 3.349942034246823, 18.190309353317396, 7.492720647435485, 4.050762879350996, 2.8904514349635795, 15.312638762718247, 30.132688503838494, 5.940101159935067, 3.5304919880620074, 10.339914442049109, 5.339427070918827, 9.78116397082055, 7.6283070632190855, 6.612887248682521, 5.704652622108402, 6.279704287901748, 4.4014721223038356, 10.212397005856527, 2.5041954981945405, 1.6917668385137479, 2.2535003760588763, 1.6587655742749452, 1.5503612424695694, 1.3897534344150981, 1.438014919696791, 1.333920806290473, 1.6576059295925032, 1.3758543139889219, 1.7154576145726965, 1.1521566991057661, 1.126519643164054, 1.6672242629510743, 1.119197928833664, 1.0981289556048872, 1.083421916190085, 1.0645851964554078, 1.0377016681375886, 1.2411566465939803, 1.0850530376376675, 1.001362280445155, 1.0059374803131198, 1.786362575442467, 0.9874329320245274, 3.210467764117811, 0.967295609872386, 0.9599964106588719, 4.174500975666465, 1.8263631880285032, 1.281798488873942, 2.383388111366365, 5.339427070918827, 3.103917677344772, 2.1601589707881534, 3.533085373325968, 3.24120368769217, 9.119911507330707, 18.540211773887112, 10.305426459961087, 30.132688503838494, 7.6283070632190855, 3.5304919880620074, 18.190309353317396, 7.492720647435485, 6.612887248682521, 14.326373161275276, 5.008055873055632, 17.45337757844935, 2.5737696493306634, 2.112223726141468, 1.831239830907434, 1.6482869095970978, 1.4251847987903827, 1.1628919747163913, 4.96455826227687, 2.638428288628931, 1.2946028800591152, 1.092798951347941, 1.041669584096852, 1.040845184690221, 1.0129439306001375, 1.0155537811552497, 1.1034924465667482, 0.9759989445743458, 1.4402090169645108, 1.878467705104729, 1.553564606180105, 0.9606287550011868, 0.9527581592075451, 0.9296174321936029, 0.9267688231217663, 1.0360522195307844, 1.1711363449188352, 0.9012528716504064, 9.78116397082055, 0.916999235207347, 0.9520935701241797, 2.011769553808228, 1.7174798773470676, 1.1461440741199, 2.1839420970458967, 3.1672635414775385, 2.4813261711529204, 2.6936651295187732, 30.132688503838494, 2.050835770374149, 1.6312693493180066, 4.269819931037478, 10.305426459961087, 1.5894340850442985, 18.540211773887112, 7.492720647435485, 5.704652622108402, 3.120619313662802, 5.026086734991513], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.9898, -4.1744, -3.6833, -4.357, -4.6135, -5.1952, -4.641, -5.234, -5.3135, -5.2789, -5.3711, -5.5301, -4.6463, -4.2381, -5.4264, -5.5699, -5.5699, -5.4315, -5.5286, -5.5889, -5.7267, -5.7737, -5.2231, -6.125, -5.397, -4.6616, -5.8242, -5.3595, -6.2088, -6.2158, -4.355, -4.0095, -4.7636, -4.8834, -3.5243, -4.0061, -4.667, -4.6394, -5.056, -4.6355, -5.1495, -5.111, -5.0804, -5.3776, -5.3604, -5.2734, -3.5508, -3.7898, -2.2917, -5.1619, -4.9922, -4.5672, -5.7754, -5.7812, -5.7359, -5.8816, -5.9689, -6.0279, -6.0354, -6.0505, -3.5913, -6.2228, -6.2742, -6.2359, -5.3044, -5.177, -6.1723, -6.0349, -5.9182, -5.5373, -6.4615, -6.4615, -5.7873, -6.4721, -6.156, -6.5017, -5.9736, -5.4972, -5.5517, -4.135, -5.3316, -4.7991, -5.5723, -4.3616, -5.0229, -5.477, -5.7083, -4.7435, -4.3607, -5.3246, -5.6151, -5.2303, -5.5062, -5.3238, -5.5279, -5.5949, -5.6709, -5.7023, -4.3188, -3.5297, -4.9653, -5.4638, -5.1816, -5.4903, -5.5949, -5.7354, -5.7071, -5.8031, -5.61, -5.8114, -5.6046, -6.0194, -6.0555, -5.6737, -6.0739, -6.0973, -6.1297, -6.1612, -6.1918, -6.0218, -6.1645, -6.2579, -6.2544, -5.697, -6.2914, -5.1141, -6.3147, -6.3298, -4.9529, -5.7334, -6.0699, -5.5532, -4.9083, -5.3991, -5.7193, -5.4062, -5.5457, -5.0383, -4.8365, -5.116, -4.715, -5.3323, -5.6373, -5.3499, -5.563, -5.5906, -5.6278, -5.7102, -2.666, -4.7501, -4.9844, -5.1669, -5.4613, -5.6275, -5.8324, -4.3826, -5.0298, -5.7471, -5.9256, -6.0008, -6.005, -6.0496, -6.0498, -5.9911, -6.1157, -5.7277, -5.4625, -5.6628, -6.1445, -6.1598, -6.2056, -6.2113, -6.1281, -6.0167, -6.2805, -3.899, -6.2781, -6.2449, -5.5054, -5.6743, -6.0661, -5.5486, -5.2668, -5.4818, -5.5109, -4.073, -5.7046, -5.8572, -5.4548, -5.1087, -5.8979, -5.1424, -5.4457, -5.5248, -5.7039, -5.7995], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9562, 0.9489, 0.9426, 0.9411, 0.908, 0.8754, 0.875, 0.8672, 0.8596, 0.8582, 0.8479, 0.8317, 0.8309, 0.8279, 0.8275, 0.8272, 0.8272, 0.8126, 0.8076, 0.8059, 0.802, 0.7938, 0.7834, 0.7206, 0.72, 0.7166, 0.7069, 0.6994, 0.6989, 0.6983, 0.6834, 0.6362, 0.6528, 0.6537, 0.4445, 0.4675, 0.4969, 0.4023, 0.5367, 0.0768, 0.4432, 0.3744, 0.2622, 0.6553, 0.5665, 0.0297, 1.2054, 1.1976, 1.1912, 1.0777, 1.0109, 0.9823, 0.9798, 0.9784, 0.9665, 0.957, 0.9283, 0.9192, 0.9108, 0.8687, 0.8632, 0.8521, 0.8434, 0.8433, 0.8363, 0.8274, 0.8191, 0.8179, 0.8139, 0.8072, 0.7809, 0.7809, 0.7797, 0.7772, 0.7757, 0.766, 0.7556, 0.7412, 0.7156, 0.5773, 0.6584, 0.5041, 0.5932, 0.1119, 0.3376, 0.4985, 0.6047, -0.0977, -0.3919, 0.2681, 0.4978, -0.1919, 0.1931, -0.2298, -0.1853, -0.1095, -0.0377, -0.1652, 1.5736, 1.5211, 1.4911, 1.3848, 1.3803, 1.3781, 1.3411, 1.3099, 1.3041, 1.2832, 1.259, 1.2439, 1.2302, 1.2134, 1.1998, 1.1895, 1.1879, 1.1835, 1.1646, 1.1507, 1.1456, 1.1366, 1.1283, 1.1151, 1.1141, 1.0973, 1.0957, 1.0939, 1.0929, 1.0854, 0.9925, 1.0387, 1.0562, 0.9527, 0.791, 0.8426, 0.8849, 0.706, 0.6528, 0.1257, -0.3821, -0.0742, -0.7463, 0.0103, 0.4756, -0.8763, -0.2025, -0.1052, -0.9155, 0.0532, 1.8488, 1.6789, 1.6423, 1.6026, 1.4134, 1.3926, 1.3911, 1.3894, 1.3745, 1.3691, 1.3601, 1.3328, 1.3294, 1.312, 1.3092, 1.2848, 1.283, 1.282, 1.2814, 1.2711, 1.2701, 1.263, 1.2418, 1.2391, 1.2109, 1.1997, 1.1979, 1.1949, 1.183, 1.1786, 1.17, 1.1592, 1.1719, 1.0447, 0.9547, 0.9838, 0.8726, -0.1042, 0.9516, 1.0278, 0.4681, -0.067, 1.0132, -0.688, -0.0853, 0.1083, 0.5325, -0.0397]}, \"token.table\": {\"Topic\": [2, 3, 3, 1, 2, 4, 3, 3, 2, 1, 3, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 3, 2, 3, 4, 3, 1, 1, 1, 2, 3, 4, 1, 2, 3, 2, 4, 4, 1, 2, 3, 3, 4, 3, 2, 3, 2, 3, 4, 4, 2, 4, 4, 2, 1, 2, 3, 4, 2, 2, 1, 2, 3, 1, 2, 3, 3, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 4, 4, 2, 4, 1, 1, 1, 2, 3, 4, 1, 2, 3, 1, 2, 1, 2, 3, 4, 3, 1, 4, 4, 2, 1, 2, 3, 2, 4, 2, 1, 2, 1, 2, 3, 4, 1, 2, 1, 2, 1, 1, 2, 3, 3, 1, 2, 3, 4, 2, 1, 2, 3, 4, 2, 4, 2, 4, 1, 2, 3, 1, 1, 3, 2, 3, 1, 2, 1, 3, 1, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 2, 1, 2, 4, 4, 2, 3, 1, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 1, 2, 1, 2, 3, 1, 2, 1, 4, 1, 2, 3, 1, 2, 3, 2, 4, 2, 4, 3, 4, 1, 4, 3, 4, 1, 4, 4, 2, 2, 1, 3, 1, 4, 1, 3, 1, 2, 3, 1, 1, 2, 1, 4, 1, 2, 3, 3, 4, 4, 2, 1, 2, 3, 4, 2, 3, 2, 1, 3, 1, 3, 2, 3, 3, 2, 4, 2, 1, 2, 3, 1, 2, 3, 4, 1, 2], \"Freq\": [0.6343049802027922, 0.8876898028970907, 0.9106398614625052, 0.9354627316348852, 0.20142779018195572, 0.6042833705458671, 0.9216139352756051, 0.599799332472494, 0.7443759333368364, 0.5660774616711977, 0.28303873083559883, 0.9699839504835617, 0.09792020418189067, 0.881281837637016, 0.41880802157368235, 0.48860935850262943, 0.06980133692894706, 0.7195520984057632, 0.9603211216230366, 0.6369726688733187, 0.31848633443665936, 0.9393329940427054, 0.32044921199512094, 0.32044921199512094, 0.32044921199512094, 0.645010964287975, 0.7526100329858733, 0.8705126298759818, 0.657901120551128, 0.2193003735170427, 0.2193003735170427, 0.9607576753094387, 0.6047175881587694, 0.3298459571775106, 0.05497432619625176, 0.5407234985763317, 0.582248452042807, 0.9150814051994872, 0.1872860115360498, 0.3745720230720996, 0.3745720230720996, 0.6032796952203439, 0.6436809875958708, 0.9230014503643761, 0.6522641839862299, 0.582934834125348, 0.4195707762537731, 0.4195707762537731, 0.6291547472206935, 0.8538715447937911, 0.49707482554700455, 0.49707482554700455, 1.0245912719056491, 0.6422872544713634, 0.25378071458956153, 0.7613421437686846, 0.6954030770493344, 0.9468693942064205, 0.5260823554033703, 0.58518565621261, 0.6733851594068604, 0.1683462898517151, 0.1683462898517151, 0.24686707906245495, 0.4937341581249099, 0.24686707906245495, 1.0416705613656123, 0.8763000164006219, 0.8875081722851893, 0.23954959067660742, 0.23954959067660742, 0.47909918135321483, 0.9475560914546646, 0.8934970073096166, 0.3157299627594289, 0.3157299627594289, 0.3157299627594289, 0.3157299627594289, 0.3505910232375925, 0.3505910232375925, 0.17529551161879625, 0.17529551161879625, 0.9599973113038716, 0.6943436599971251, 0.4876060845269744, 0.4876060845269744, 0.9447653290865146, 0.6310820944947221, 0.02041400083127949, 0.9594580390701362, 0.02041400083127949, 0.45788759754786873, 0.37807734491224304, 0.5041031265496574, 0.12602578163741435, 0.2541098952533807, 0.7623296857601419, 0.3459667192133952, 0.6919334384267904, 0.559796770122274, 0.90621372453546, 0.7496696919968734, 0.7526100329860838, 0.9652023142741666, 0.9872214737567274, 0.5106788703748745, 0.6048795102013748, 0.3024397551006874, 0.1512198775503437, 0.6422038454417437, 0.32110192272087185, 0.6205527594074037, 0.16122310661628966, 0.8061155330814483, 0.20447464186946027, 0.20447464186946027, 0.10223732093473013, 0.5111866046736506, 0.3305280564313952, 0.6610561128627904, 0.7843841550360087, 0.2614613850120029, 0.7265905447526748, 0.627087693369952, 0.5245451685478675, 0.5910980031258448, 0.9940975652768483, 0.5822175359080343, 0.09703625598467237, 0.19407251196934475, 0.09703625598467237, 0.9480655600107036, 0.763927727800836, 0.3712413948717713, 0.3712413948717713, 0.3712413948717713, 0.44597946520025583, 0.44597946520025583, 0.8988124422880027, 0.974023504825269, 0.8151004836835831, 0.13585008061393053, 0.13585008061393053, 0.5892783552496624, 0.8998998963834087, 0.14998331606390145, 0.5935697397301398, 0.7986596898852137, 0.2504625430802669, 0.5009250861605338, 0.708180962136676, 1.033810129802955, 0.8144825109535951, 0.39935656683872284, 0.19967828341936142, 0.19967828341936142, 0.5641713648562899, 0.19911930524339644, 0.09955965262169822, 0.13274620349559763, 0.8531255671407867, 0.2843751890469289, 0.7268211392969124, 0.7411733237123983, 0.7056726751452235, 0.2822690700580894, 1.0409848703714522, 0.9846844338095453, 0.32217349296951847, 0.32217349296951847, 0.8585435613385128, 0.7737007926745091, 0.19342519816862727, 0.2669257395422229, 0.40038860931333436, 0.13346286977111144, 0.13346286977111144, 0.10787363296555717, 0.7011786142761216, 0.10787363296555717, 0.053936816482778586, 0.882442057192647, 0.9783490220735274, 0.2985126279132268, 0.5970252558264536, 0.71836083711331, 0.26122212258665817, 1.0127270091647707, 0.5050419040393571, 0.33669460269290474, 0.7509597513483777, 0.8724906602757415, 0.7054705092854049, 0.23515683642846832, 0.23515683642846832, 0.2832466419358538, 0.5664932838717076, 0.2832466419358538, 0.40301029813237377, 0.40301029813237377, 0.37901352267552196, 0.7580270453510439, 0.9636681049137624, 0.6066904943414475, 0.7026057418002314, 0.23420191393341044, 0.8679374956341781, 0.7016633918974887, 0.8925117527251372, 0.8599251020232401, 0.7770703180527914, 0.7734659867730146, 0.6817926283208026, 0.8606027432292045, 0.8057000723834742, 0.6130195484995015, 0.6130195484995015, 0.9024163486733034, 0.6028579417782438, 0.35704191124873613, 0.7140838224974723, 0.9087868533190446, 1.0031580475124107, 0.8050238838611569, 0.26834129462038564, 0.968829645915482, 0.5323487847475386, 0.31148109044315075, 0.31148109044315075, 0.6229621808863015, 0.5475362220147822, 0.7724376450903131, 1.0495842941211315, 0.8763000172625426, 0.5243627408873642, 0.2621813704436821, 0.13109068522184106, 0.13109068522184106, 0.5823853881071747, 0.29119269405358733, 0.9191107866047413, 0.6170547095187521, 0.30852735475937604, 0.8397906138709915, 0.9986395728381646, 0.46292889251347136, 0.46292889251347136, 0.7801538297010309, 0.9644947952577377, 0.5460781177441243, 0.5383921922030883, 0.8948354380786523, 0.09942615978651692, 0.09942615978651692, 0.5968858394571788, 0.19896194648572624, 0.19896194648572624, 0.19896194648572624, 0.940668119463854, 0.6517123183295694], \"Term\": [\"absolut\", \"accessori\", \"accuraci\", \"amaz\", \"amazon\", \"amazon\", \"appli\", \"aspect\", \"audio\", \"averag\", \"averag\", \"awesom\", \"bad\", \"bad\", \"batteri\", \"batteri\", \"batteri\", \"bed\", \"best\", \"better\", \"better\", \"boom\", \"box\", \"box\", \"box\", \"brilliant\", \"browser\", \"budget\", \"buy\", \"buy\", \"buy\", \"camara\", \"camera\", \"camera\", \"camera\", \"capac\", \"care\", \"center\", \"charg\", \"charg\", \"charg\", \"charger\", \"choic\", \"clean\", \"clear\", \"colour\", \"condit\", \"condit\", \"cost\", \"cover\", \"custom\", \"custom\", \"cwllotap\", \"damag\", \"day\", \"day\", \"deal\", \"defect\", \"deliveri\", \"dislik\", \"display\", \"display\", \"display\", \"drain\", \"drain\", \"drain\", \"email\", \"est\", \"everi\", \"everyth\", \"everyth\", \"everyth\", \"excel\", \"expand\", \"expect\", \"expect\", \"expect\", \"expect\", \"experi\", \"experi\", \"experi\", \"experi\", \"fab\", \"fabul\", \"face\", \"face\", \"featur\", \"function\", \"good\", \"good\", \"good\", \"got\", \"great\", \"great\", \"great\", \"hang\", \"hang\", \"happi\", \"happi\", \"headphon\", \"help\", \"higher\", \"html\", \"hype\", \"ine\", \"interfac\", \"issu\", \"issu\", \"issu\", \"item\", \"item\", \"job\", \"life\", \"life\", \"like\", \"like\", \"like\", \"like\", \"look\", \"look\", \"love\", \"love\", \"low\", \"main\", \"mark\", \"memori\", \"mirag\", \"mobil\", \"mobil\", \"mobil\", \"mobil\", \"money\", \"month\", \"need\", \"need\", \"need\", \"new\", \"new\", \"nic\", \"nice\", \"nord\", \"nord\", \"nord\", \"note\", \"oneplus\", \"oneplus\", \"open\", \"outstand\", \"overal\", \"overal\", \"oxygen\", \"pcs\", \"perfect\", \"perform\", \"perform\", \"perform\", \"phone\", \"phone\", \"phone\", \"phone\", \"photo\", \"photo\", \"piec\", \"play\", \"plus\", \"plus\", \"pnzz\", \"poco\", \"poor\", \"poor\", \"premium\", \"price\", \"price\", \"problem\", \"problem\", \"problem\", \"problem\", \"product\", \"product\", \"product\", \"product\", \"proof\", \"proper\", \"purchas\", \"purchas\", \"qualiti\", \"qualiti\", \"qualitynot\", \"rang\", \"rang\", \"rate\", \"reach\", \"realli\", \"realli\", \"realli\", \"renew\", \"renew\", \"renew\", \"replac\", \"replac\", \"return\", \"return\", \"rob\", \"scratch\", \"screen\", \"screen\", \"seal\", \"second\", \"segment\", \"seller\", \"servic\", \"short\", \"shot\", \"sim\", \"simpli\", \"slow\", \"slow\", \"smooth\", \"space\", \"speaker\", \"speaker\", \"storag\", \"super\", \"superb\", \"superb\", \"support\", \"thank\", \"thing\", \"thing\", \"thing\", \"total\", \"unabl\", \"upton\", \"urdu\", \"use\", \"use\", \"use\", \"use\", \"user\", \"user\", \"valu\", \"variant\", \"variant\", \"video\", \"waist\", \"want\", \"want\", \"warp\", \"wast\", \"west\", \"wonder\", \"work\", \"work\", \"work\", \"worst\", \"worst\", \"worst\", \"worst\", \"worth\", \"wow\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 4, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el2678412573646265046370858989\", ldavis_el2678412573646265046370858989_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el2678412573646265046370858989\", ldavis_el2678412573646265046370858989_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el2678412573646265046370858989\", ldavis_el2678412573646265046370858989_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "1     -0.097645  0.058250       1        1  37.030862\n",
              "2     -0.023497 -0.105243       2        1  29.000702\n",
              "3      0.031661  0.017124       3        1  18.655348\n",
              "0      0.089482  0.029869       4        1  15.313088, topic_info=         Term       Freq      Total Category  logprob  loglift\n",
              "431      good  48.000000  48.000000  Default  30.0000  30.0000\n",
              "667      nice  17.000000  17.000000  Default  29.0000  29.0000\n",
              "640     money  13.000000  13.000000  Default  28.0000  28.0000\n",
              "76        bad  10.000000  10.000000  Default  27.0000  27.0000\n",
              "1114     valu  10.000000  10.000000  Default  26.0000  26.0000\n",
              "...       ...        ...        ...      ...      ...      ...\n",
              "796   product   1.426892  18.540212   Topic4  -5.1424  -0.6880\n",
              "792   problem   1.053606   7.492721   Topic4  -5.4457  -0.0853\n",
              "351    experi   0.973493   5.704653   Topic4  -5.5248   0.1083\n",
              "122       box   0.813906   3.120619   Topic4  -5.7039   0.5325\n",
              "1165    worst   0.739661   5.026087   Topic4  -5.7995  -0.0397\n",
              "\n",
              "[226 rows x 6 columns], token_table=      Topic      Freq       Term\n",
              "term                            \n",
              "4         2  0.634305    absolut\n",
              "6         3  0.887690  accessori\n",
              "9         3  0.910640   accuraci\n",
              "30        1  0.935463       amaz\n",
              "31        2  0.201428     amazon\n",
              "...     ...       ...        ...\n",
              "1165      2  0.198962      worst\n",
              "1165      3  0.198962      worst\n",
              "1165      4  0.198962      worst\n",
              "1166      1  0.940668      worth\n",
              "1170      2  0.651712        wow\n",
              "\n",
              "[260 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 4, 1])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pyLDAvis.sklearn.prepare(lda_tfIDF,tfidfObject,tf_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jZ5ekT_07JJ"
      },
      "outputs": [],
      "source": [
        "#interpreting results of topic\n",
        "#APPLYING LDA TRANSFORMATION TO BOW OBJECT\n",
        "\n",
        "topic_results = lda_tfIDF.transform(tfObject)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.01918958, 0.47842533, 0.15575044, 0.34663465],\n",
              "       [0.01028827, 0.32239939, 0.01044414, 0.6568682 ],\n",
              "       [0.00494582, 0.65150072, 0.3126417 , 0.03091177],\n",
              "       ...,\n",
              "       [0.12502267, 0.62494304, 0.12501379, 0.1250205 ],\n",
              "       [0.03642009, 0.30913009, 0.61723193, 0.03721789],\n",
              "       [0.25118936, 0.64879953, 0.09296286, 0.00704825]])"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topic_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYOf6jjH07JJ",
        "outputId": "f75cd53a-5c07-4f6a-fe65-e212f5663bba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.  , 0.37, 0.01, 0.61])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topic_results[4].round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpzzMtIw07JK",
        "outputId": "09fb26bc-1eaa-41a8-85ec-2d42540b7643"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topic_results[4].argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUm88V2L07JK",
        "outputId": "dc7071f5-9fdd-4fa8-cdf9-341fecdbfca5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'regard one plus feel gone see sell gb gt variant flash sale blue variant yet avail sale base variant month gt month wait buy base variant get one answer tri make everi bit sell higher variant forc make peopl buy higher variant even sell point advertis still k one plus still impress phone everi aspect camera perform regard nord front camera wast even half qualiti compar year old oplus great oplus feel give everi penni spend oplus till gone never gon na get trust back peopl oplus write long wait phone struggl get phone one flash sale phone issu would better look back oplus earn place look current stand need reason'"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_raw[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkZj4lIF07JK"
      },
      "outputs": [],
      "source": [
        "# Try the same code with your custom function for preprocessing and create BOW and TFIDF object. Apply the same to LDA\n",
        "# and see if you get better outputs !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categories LDA = 4\n",
        "### 1. Good Experience(phone features)\n",
        "### 2. Bad Experience(phone features)\n",
        "### 3. Phone detailed features reviews\n",
        "### 4. Delivery and After sales service\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "LDA Demo1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
